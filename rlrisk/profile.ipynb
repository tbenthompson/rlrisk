{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "concerned-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "antique-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import time\n",
    "import copy\n",
    "\n",
    "import pyinstrument\n",
    "import numpy as np\n",
    "import risk_ext\n",
    "\n",
    "import torch\n",
    "\n",
    "from env import DumbPlayer, play_games\n",
    "from vpg import VPGPlayer, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "designed-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_spec = dict(\n",
    "    n_players=3,\n",
    "    n_territories=8,\n",
    "    baseline_reinforcements=3,\n",
    "    n_attacks_per_turn=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "demographic-contributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = [VPGPlayer()] + [DumbPlayer() for i in range(game_spec['n_players'] - 1)]\n",
    "#players = [DumbPlayer()] + [DumbPlayer() for i in range(game_spec['n_players'] - 1)]\n",
    "nn_player_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "identified-cliff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_games(game_spec, players, np.arange(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "marked-arthur",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_games(env, players, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "instructional-concert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 1.60376 s\n",
       "File: <ipython-input-5-0de797d7b9be>\n",
       "Function: act at line 6\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     6                                           def act(self, player_idx, states):\n",
       "     7      3323       4683.0      1.4      0.3      if states.shape[0] == 0:\n",
       "     8        14         89.0      6.4      0.0          return np.array([]).reshape((0,2))\n",
       "     9      3309      11263.0      3.4      0.7      state_matrix = states[:, n_max_players:].reshape((states.shape[0], n_max_territories, n_max_players+1))\n",
       "    10      3309      45570.0     13.8      2.8      attack_from = (state_matrix[:,:,player_idx + 1] == 1).argmax(axis = 1)\n",
       "    11                                               \n",
       "    12      3309      42091.0     12.7      2.6      states_torch = torch.as_tensor(states, dtype=torch.float32)\n",
       "    13      3309    1471464.0    444.7     91.8      attack_to = self.get_action(states_torch)\n",
       "    14                                               \n",
       "    15      3309      28604.0      8.6      1.8      return np.array([attack_from, attack_to]).T\n",
       "\n",
       "Total time: 0.200132 s\n",
       "File: <ipython-input-5-0de797d7b9be>\n",
       "Function: act_dumb at line 20\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    20                                           def act_dumb(self, player_idx, states):\n",
       "    21      6646      26411.0      4.0     13.2      state_matrix = states[:, n_max_players:].reshape((states.shape[0], n_max_territories, n_max_players+1))\n",
       "    22      6646      76300.0     11.5     38.1      attack_from = (state_matrix[:,:,player_idx + 1] == 1).argmax(axis = 1)\n",
       "    23      6646      64814.0      9.8     32.4      attack_to = (state_matrix[:,:,player_idx + 1] != 1).argmax(axis = 1)\n",
       "    24      6646      32607.0      4.9     16.3      return np.array([attack_from, attack_to]).T\n",
       "\n",
       "Total time: 2.1979 s\n",
       "File: <ipython-input-5-0de797d7b9be>\n",
       "Function: play_games at line 31\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    31                                           def play_games(env, players, n_games):\n",
       "    32         2        633.0    316.5      0.0      game_set = risk_ext.start_game_set(\n",
       "    33         1          1.0      1.0      0.0          game_spec[\"n_players\"],\n",
       "    34         1          1.0      1.0      0.0          game_spec[\"n_territories\"],\n",
       "    35         1          1.0      1.0      0.0          game_spec[\"baseline_reinforcements\"],\n",
       "    36         1          1.0      1.0      0.0          game_spec[\"n_attacks_per_turn\"],\n",
       "    37         1         51.0     51.0      0.0          [i for i in range(n_games)]\n",
       "    38                                               )\n",
       "    39                                           \n",
       "    40         1         15.0     15.0      0.0      player_idxs = np.empty(n_games, dtype=np.int32)\n",
       "    41         1         11.0     11.0      0.0      states = np.empty((n_games, state_dim), dtype=np.float32)\n",
       "    42                                               while True:\n",
       "    43      3323      46458.0     14.0      2.1          game_set.get_idxs_states(player_idxs, states)\n",
       "    44                                                   \n",
       "    45      3323      19299.0      5.8      0.9          actions = np.zeros((n_games, 2), dtype=np.int32)\n",
       "    46     13292      18265.0      1.4      0.8          for i in range(len(players)):\n",
       "    47      9969      55490.0      5.6      2.5              this_player_idxs = player_idxs == i\n",
       "    48      9969    2017789.0    202.4     91.8              actions[this_player_idxs] = players[i].act(i, states[this_player_idxs])\n",
       "    49                                                   \n",
       "    50      3323      39878.0     12.0      1.8          if game_set.step(actions):\n",
       "    51         1          1.0      1.0      0.0              break\n",
       "    52         1          4.0      4.0      0.0      return game_set.winners"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f play_games -f act -f act_dumb play_games(env, players, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dangerous-certification",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbent/Dropbox/active/rlrisk/rlrisk/vpg.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1614378073166/work/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  attack_to = self.get_action(torch.as_tensor(state_vec, dtype=torch.float32))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 15.1733 s\n",
       "File: /home/tbent/Dropbox/active/rlrisk/rlrisk/env.py\n",
       "Function: faceoff at line 67\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    67                                               def faceoff(self, players, n_games):\n",
       "    68         1         14.0     14.0      0.0          winners = np.empty(n_games, dtype=np.int32)\n",
       "    69       251        168.0      0.7      0.0          for i in range(n_games):\n",
       "    70       250   15173017.0  60692.1    100.0              winners[i] = self.play_game(players)\n",
       "    71         1        140.0    140.0      0.0          winner_counts = np.unique(winners, return_counts=True)\n",
       "    72         1         10.0     10.0      0.0          return winners, winner_counts[0], winner_counts[1] / n_games\n",
       "\n",
       "Total time: 14.563 s\n",
       "File: /home/tbent/Dropbox/active/rlrisk/rlrisk/env.py\n",
       "Function: play_game at line 74\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    74                                               def play_game(self, players, verbose=False, max_turns=None, plot_each_turn=False):\n",
       "    75       250       2851.0     11.4      0.0          self.reset()\n",
       "    76       250        179.0      0.7      0.0          next_turn_plot = 0\n",
       "    77                                                   while True:\n",
       "    78    212859      88909.0      0.4      0.6              if plot_each_turn and self.game.turn_idx == next_turn_plot:\n",
       "    79                                                           vis(self.game)\n",
       "    80                                                           next_turn_plot += 1\n",
       "    81    212859   13003313.0     61.1     89.3              action = players[self.game.player_idx].act(self.game, self.game.board_state)\n",
       "    82    212859     156036.0      0.7      1.1              if verbose:\n",
       "    83                                                           print(\n",
       "    84                                                               f\"turn={self.game.turn_idx}, player={self.game.player_idx}, phase={self.game.phase}, action={action}, board={self.game.board_state}\"\n",
       "    85                                                           )\n",
       "    86    212859    1087618.0      5.1      7.5              _, _, done = self.step(action)\n",
       "    87    212859     123361.0      0.6      0.8              if done:\n",
       "    88       250        119.0      0.5      0.0                  break\n",
       "    89    212609     100394.0      0.5      0.7              if max_turns is not None:\n",
       "    90                                                           if self.game.turn_idx > max_turns:\n",
       "    91                                                               break\n",
       "    92       250        180.0      0.7      0.0          return self.game.player_idx\n",
       "\n",
       "Total time: 10.0642 s\n",
       "File: /home/tbent/Dropbox/active/rlrisk/rlrisk/vpg.py\n",
       "Function: act at line 66\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    66                                               def act(self, game, state_vec):\n",
       "    67     25510     119038.0      4.7      1.2          owner_col = vec_to_territory_matrix(game, state_vec)[:, game.player_idx + 1]\n",
       "    68     25510     167662.0      6.6      1.7          attack_from = (owner_col == 1).argmax()\n",
       "    69     25510    9743811.0    382.0     96.8          attack_to = self.get_action(torch.as_tensor(state_vec, dtype=torch.float32))\n",
       "    70     25510      33670.0      1.3      0.3          return attack_from, attack_to"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f env.faceoff -f env.play_game -f VPGPlayer.act env.faceoff([VPGPlayer(env)] + [DumbPlayer() for i in range(game_spec['n_players'] - 1)], 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "honest-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tbent/Dropbox/active/rlrisk/rlrisk/vpg.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /opt/conda/conda-bld/pytorch_1614378073166/work/torch/csrc/utils/tensor_numpy.cpp:143.)\n",
      "  attack_to = self.get_action(torch.as_tensor(state_vec, dtype=torch.float32))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 22:34:21  Samples:  2732\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 2.756     CPU time: 2.756\n",
      "/   _/                      v3.4.1\n",
      "\n",
      "Program: /home/tbent/.miniconda3/envs/rlrisk/lib/python3.9/site-packages/ipykernel_launcher.py -f /home/tbent/.local/share/jupyter/runtime/kernel-948caa3d-9119-4b9d-a4a7-2469db6d47c6.json\n",
      "\n",
      "\u001b[31m2.755\u001b[0m run_code\u001b[0m  \u001b[2mIPython/core/interactiveshell.py:3396\u001b[0m\n",
      "└─ \u001b[31m2.755\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m<ipython-input-6-82be53c98072>:7\u001b[0m\n",
      "   └─ \u001b[31m2.754\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfaceoff\u001b[0m  \u001b[2menv.py:67\u001b[0m\n",
      "      └─ \u001b[31m2.754\u001b[0m \u001b[48;5;24m\u001b[38;5;15mplay_game\u001b[0m  \u001b[2menv.py:74\u001b[0m\n",
      "         ├─ \u001b[31m2.040\u001b[0m \u001b[48;5;24m\u001b[38;5;15mact\u001b[0m  \u001b[2mvpg.py:66\u001b[0m\n",
      "         │  ├─ \u001b[31m1.912\u001b[0m \u001b[48;5;24m\u001b[38;5;15mget_action\u001b[0m  \u001b[2mvpg.py:59\u001b[0m\n",
      "         │  │  ├─ \u001b[33m1.557\u001b[0m \u001b[48;5;24m\u001b[38;5;15mget_policy\u001b[0m  \u001b[2mvpg.py:55\u001b[0m\n",
      "         │  │  │  ├─ \u001b[33m0.777\u001b[0m __init__\u001b[0m  \u001b[2mtorch/distributions/categorical.py:49\u001b[0m\n",
      "         │  │  │  │     [32 frames hidden]  \u001b[2mtorch, <built-in>\u001b[0m\n",
      "         │  │  │  └─ \u001b[33m0.764\u001b[0m _call_impl\u001b[0m  \u001b[2mtorch/nn/modules/module.py:866\u001b[0m\n",
      "         │  │  │        [36 frames hidden]  \u001b[2mtorch, <built-in>\u001b[0m\n",
      "         │  │  ├─ \u001b[32m0.252\u001b[0m sample\u001b[0m  \u001b[2mtorch/distributions/categorical.py:108\u001b[0m\n",
      "         │  │  │     [38 frames hidden]  \u001b[2mtorch, <built-in>\u001b[0m\n",
      "         │  │  └─ \u001b[92m\u001b[2m0.084\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
      "         │  ├─ \u001b[92m\u001b[2m0.059\u001b[0m _VariableFunctionsClass.as_tensor\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
      "         │  │     [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "         │  └─ \u001b[92m\u001b[2m0.047\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
      "         ├─ \u001b[32m0.403\u001b[0m \u001b[48;5;24m\u001b[38;5;15mact\u001b[0m  \u001b[2menv.py:96\u001b[0m\n",
      "         │  ├─ \u001b[32m0.259\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
      "         │  ├─ \u001b[92m\u001b[2m0.089\u001b[0m \u001b[48;5;24m\u001b[38;5;15mvec_to_territory_matrix\u001b[0m  \u001b[2menv.py:8\u001b[0m\n",
      "         │  │  ├─ \u001b[92m\u001b[2m0.058\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
      "         │  │  └─ \u001b[92m\u001b[2m0.031\u001b[0m ndarray.reshape\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
      "         │  │        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "         │  └─ \u001b[92m\u001b[2m0.055\u001b[0m ndarray.argmax\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
      "         │        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "         ├─ \u001b[32m0.179\u001b[0m \u001b[48;5;24m\u001b[38;5;15mstep\u001b[0m  \u001b[2menv.py:56\u001b[0m\n",
      "         │  ├─ \u001b[32m0.146\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
      "         │  └─ \u001b[92m\u001b[2m0.033\u001b[0m GameState.step\u001b[0m  \u001b[2m<built-in>:0\u001b[0m\n",
      "         │        [2 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "         └─ \u001b[92m\u001b[2m0.131\u001b[0m [self]\u001b[0m  \u001b[2m\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyinstrument import Profiler\n",
    "profiler = Profiler()\n",
    "profiler.start()\n",
    "\n",
    "#play_games(env, players, 50)\n",
    "#play_games(env, players, 50)\n",
    "env.faceoff([VPGPlayer(env)] + [DumbPlayer() for i in range(game_spec['n_players'] - 1)], 50)\n",
    "#train(env, players, 2, 20000, [0])\n",
    "\n",
    "profiler.stop()\n",
    "print(profiler.output_text(unicode=True, color=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
